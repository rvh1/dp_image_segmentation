{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Information \n",
    "When I developed the proof-of-concept for Part 2 (Progress Report for this project), I followed the standards that are used for implementation of most clustering processes: read in all data points (aka pixels) as data stream and process the information based on the RGB value for each pixel (one after the other). \n",
    "\n",
    "This approach allowed me to achieve successful KMEANS clustering for images, though it was very slow (run times up to several minutes, in some cases hours)! \n",
    "\n",
    "Once I had completed the implementation of the Density Peak (DP) clustering algorithm, it became clear that I had reached a dead end with my code: not a single DP segmentation process could complete within hours of running! \n",
    "I started researching alternative Python libraries, but they all had the same problem: once faced with the processing of 100,000+ data points (aka pixels), we can't just stream the data any longer to perform basic calculations, such as: find the maximum possible distance between any two points in the set, or find the closest pixel for each pixel in the image. All these operations are of the order O(N^2) and cannot be completed by any program in reasonable timeframes. \n",
    "\n",
    "After hitting this dead end, I thought about alternative options and it became clear that two things would help to solve this issue: \n",
    "- Somehow using indexed data points to improve access to relevant data (pixels) without the need to loop through all data records (in relational database terms this is a 'full table scan' vs 'indexed data access') \n",
    "- meaningful reduction of data points for processing, without compromising on the quality of the image too much\n",
    "\n",
    "I conceived the following two approaches to implement those two objectives: \n",
    "\n",
    "Ad 1: It was beyond the time and scope of this project to set up a relational database schema for the image pixels. However there is the concept of 'Dictionaries' available in Python. It uses a hash-key to access data for a particular key (or index) and offers excellent performance. I have decided to convert all list loops, eg to find an attribute for a particular pixel, into dictionaries. This offers significant improvements for the overall KMEANS and DP clustering algorithms. \n",
    "\n",
    "Ad 2: Rather than working with individual pixels, I have divided the RGB cube (with length 256) into several sub-cubes of equal length (e.g. cubes with length to the power of 2). For each mini-cube within the overall RGB cube, I have then counted the number of pixels that sit within the mini-cube, and assigned this number to the pixel in the centre of the mini-cube. Completing this process for an image with 100,000+ pixels, allowed me to compress the number of distinct data points (pixels) below 1,000 in most cases! \n",
    "\n",
    "With the 2 steps described above, the structure of the input data had been significantly changed, and the traditional KMEANS clustering process did no longer work. Code became far more complex (for example, the KMEANS implementation increased from about 50 lines to over 150 lines of code!) However, the results were astounding: KMEANS processes, that ran for 10 min and longer could now be completed in under 5 sec! \n",
    "\n",
    "The approach was a compromise: giving away a little bit of image accuracy allowed me to achieve very good runtimes for KMEANS and DP clustering algorithms. \n",
    "\n",
    "The following section outlines the process that had been used to determine the best value for the length of the mini-cubes (called granularity in this notebook). The optimal parameter for the mini-cube length was then used as the default setting in the GUI interface and the tuning of the hyper-parameters of the DP clustering algorithm. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGB Cubes for Preprocessing of Images\n",
    "\n",
    "We start by importing library matplotlib for inline display of images in this workbook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display all images inline\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we import code that has been developed for the slicing of the cubes. Library PIL is imported so we can process pixel stream between image objects.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dp import DPImage\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the image pre-processing with all possible side lengths for the mini cubes: 1,2,4,8,16,32,64,128 and 256.\n",
    "\n",
    "Please note: \n",
    "\n",
    "- If length of cube is set to 1, then the quality of the image will not decrease: each pixel is assigned to itself (its own image cube, which is effectively just a point) \n",
    "- If length of the cube is set to 256, we are left with a single cube, the RGB space itself! Each pixel will be assigned to the centre of this space which is (128,128,128) and grey! \n",
    "\n",
    "This illustrates that the optimal value for the length of the cube most be somewhere between 1 and 256. I've tested the process against a beautiful picture of the Fox glacier (taken in January 2018 during holidays in New Zealand). \n",
    "\n",
    "We start by generating images with side length 1, 2, 4, 8, 16 and 32:\n",
    "\n",
    "#### In the original image k.jpeg, there are 139,968 pixels. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"images/k.jpeg\"\n",
    "img1 = Image.open(img_name)\n",
    "img2 = Image.open(img_name)\n",
    "\n",
    "dist = 'Euclidean'    \n",
    "dp = DPImage(dist) \n",
    "\n",
    "for granularity in [1,2,4,8,16,32]: \n",
    "    dp.GRANULARITY = granularity\n",
    "    dp.pre_process_img(img1)\n",
    "    img2.putdata(dp.get_pre_processed_data())\n",
    "    \n",
    "    f, axarr = plt.subplots(1,2)\n",
    "    f.suptitle(\"Granularity = \"+str(dp.GRANULARITY)+\", Number of Distinct Pixels = \"+str(len(dp.pnts.keys())), fontsize=16)\n",
    "    axarr[0].set_title('Original')\n",
    "    axarr[0].imshow(img1)\n",
    "    axarr[0].axis('off')\n",
    "    axarr[1].set_title('Clustered')\n",
    "    axarr[1].imshow(img2)   \n",
    "    axarr[1].axis('off') \n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we test against the remaining side lengths (64, 128 and 256). The purpose of this section is more to cross-check that the implemented algorithm works correctly for all specificed side lengths, but the generated images lost too much of their details and should no longer be used in DP or KMEANS clustering: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"images/k.jpeg\"\n",
    "img1 = Image.open(img_name)\n",
    "img2 = Image.open(img_name)\n",
    "\n",
    "dist = 'Manhattan'    \n",
    "dp = DPImage(dist) \n",
    "\n",
    "for granularity in [64,128,256]: \n",
    "    dp.GRANULARITY = granularity\n",
    "    dp.pre_process_img(img1)\n",
    "    img2.putdata(dp.get_pre_processed_data())\n",
    "    \n",
    "    f, axarr = plt.subplots(1,2)\n",
    "    f.suptitle(\"Granularity = \"+str(dp.GRANULARITY)+\", Number of Distinct Pixels = \"+str(len(dp.pnts.keys())), fontsize=16)\n",
    "    axarr[0].set_title('Original')\n",
    "    axarr[0].imshow(img1)\n",
    "    axarr[0].axis('off')\n",
    "    axarr[1].set_title('Clustered')\n",
    "    axarr[1].imshow(img2)   \n",
    "    axarr[1].axis('off') \n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: with granularity = 1, there is no difference between the original and the pre=processed image. With granularity = 256, only one large 'cube' remains in the RGB space. Its centre is (128,128,128) and this is exactly the colour that is shown for the pre-processed image. \n",
    "\n",
    "However, it is remarkable to note that cube size 128 produces a total of 8 clusters (2^3), which in themselves could be considered as a reasonable segmentation of the initial image with a fix number of 8 segments! \n",
    "\n",
    "#### Result: we achieve reasonable image quality in the pre-processed image with GRANULARITY=16. We will use this as standard value for all image clustering processes. Please note: the value is configurable in the app.ini file, in the global section and may be altered.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation of Average Distance between Pixels in Mini RGB-Cube\n",
    "All pixels in a data cube are now centred in the centre of the cube. This means that the algorithm will calculate a distance of 0 for all data points in the cube. However, this is not correct and we use the estimated average distance between two points in a cube. \n",
    "Rather than mathematically calculating this mean, I have decided to run a simple simulation to estimate the mean differences for Euclidean, Manhattan and Supremum distances. Those values are then used in the density calculation for all pixels in the DP algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "from math   import sqrt\n",
    "e=0.0\n",
    "m=0.0\n",
    "s=0.0\n",
    "n=1000000\n",
    "for i in range(n):\n",
    "    e = e + sqrt(pow(random() - random(),2) + pow(random() - random(),2) + pow(random() - random(),2)) \n",
    "    m = m + abs(random() - random()) + abs(random() - random()) + abs(random() - random()) \n",
    "    s = s + max(abs(random() - random()),abs(random() - random()),abs(random() - random())) \n",
    "print(\"Average Manhattan Distance: \"+str(m/n))\n",
    "print(\"Average Euclidean Distance: \"+str(e/n))\n",
    "print(\"Average Supremum Distance:  \"+str(s/n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We will use the following mean values for distances between pixels in the same cube: \n",
    "- Manhattan Distance: 1.00\n",
    "- Euclidean Distance: 0.66 \n",
    "- Supremum Distance:  0.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e=0.0\n",
    "m=0.0\n",
    "s=0.0\n",
    "n=1000000\n",
    "for i in range(n):\n",
    "    e = e + sqrt(pow(1+random() - random(),2) + pow(random() - random(),2) + pow(random() - random(),2)) \n",
    "    m = m + abs(1+random() - random()) + abs(random() - random()) + abs(random() - random()) \n",
    "    s = s + max(abs(1+random() - random()),abs(random() - random()),abs(random() - random())) \n",
    "print(\"Average Manhattan Distance: \"+str(m/n))\n",
    "print(\"Average Euclidean Distance: \"+str(e/n))\n",
    "print(\"Average Supremum Distance:  \"+str(s/n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e=0.0\n",
    "m=0.0\n",
    "s=0.0\n",
    "n=1000000\n",
    "for i in range(n):\n",
    "    e = e + sqrt(pow(2+random() - random(),2) + pow(random() - random(),2) + pow(random() - random(),2)) \n",
    "    m = m + abs(2+random() - random()) + abs(random() - random()) + abs(random() - random()) \n",
    "    s = s + max(abs(2+random() - random()),abs(random() - random()),abs(random() - random())) \n",
    "print(\"Average Manhattan Distance: \"+str(m/n))\n",
    "print(\"Average Euclidean Distance: \"+str(e/n))\n",
    "print(\"Average Supremum Distance:  \"+str(s/n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This concludes the workbook for the pre-processing of images in mini-cubes. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
